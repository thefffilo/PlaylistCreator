{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY4BsVjdtvI1"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "!pip install pygit2==1.12.2\n",
        "%cd /content\n",
        "folder_path = \"/content/PlaylistCreator\"\n",
        "shutil.rmtree(folder_path, ignore_errors=True)\n",
        "!git clone https://github.com/thefffilo/PlaylistCreator.git\n",
        "%cd /content/PlaylistCreator/frontend\n",
        "!npm i\n",
        "!npm run build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFV4ux8y5CUR"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(8084)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xwMJICGYnFd"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAZtDcheYrn1"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMZxt_TyY3Qp"
      },
      "outputs": [],
      "source": [
        "!pip install auto-gptq\n",
        "!pip install optimum\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-3xpY_TEI35"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch==2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-transformers\n",
        "# !pip install transformers"
      ],
      "metadata": {
        "id": "2DIWVSalN3MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxT3PytKY7xE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "c8e45a44-90ab-46ff-dde3-c3899474b6ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\n/usr/local/lib/python3.10/dist-packages/_XLAC.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c109TupleTypeC1ESt6vectorINS_4Type24SingletonOrSharedTypePtrIS2_EESaIS4_EESt8optionalINS_13QualifiedNameEESt10shared_ptrINS_14FunctionSchemaEE",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioClassificationPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautomatic_speech_recognition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutomaticSpeechRecognitionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/audio_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_end_docstrings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torchaudio_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_pipeline_init_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelcard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modelcard.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m )\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m from .utils import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer_pt_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAcceleratorConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m_XLAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/_XLAC.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c109TupleTypeC1ESt6vectorINS_4Type24SingletonOrSharedTypePtrIS2_EESaIS4_EESt8optionalINS_13QualifiedNameEESt10shared_ptrINS_14FunctionSchemaEE",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ca86b5eb2bf4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare_model_for_kbit_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoraConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_peft_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1393\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\n/usr/local/lib/python3.10/dist-packages/_XLAC.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c109TupleTypeC1ESt6vectorINS_4Type24SingletonOrSharedTypePtrIS2_EESaIS4_EESt8optionalINS_13QualifiedNameEESt10shared_ptrINS_14FunctionSchemaEE"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from peft import LoraConfig, get_peft_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM7J90t-ZqYF"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1DEu9aRZOWc",
        "outputId": "96077b97-6c5a-45bf-c83c-2492578fcb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# load model from hub\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "model_name = \"fffilo/mistral-genre-classificator\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             device_map=\"auto\",\n",
        "                                             trust_remote_code=False,\n",
        "                                             revision=\"main\")\n",
        "\n",
        "config = PeftConfig.from_pretrained(\"fffilo/mistral-genre-classificator\")\n",
        "model = PeftModel.from_pretrained(model, \"fffilo/mistral-genre-classificator\")\n",
        "\n",
        "# load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_YXF1zXZcL8"
      },
      "outputs": [],
      "source": [
        "#Codice per estrarre solo i primi 3 generi utili\n",
        "#Utile come parser dell'output del LLM, in questo modo viene standardizzato\n",
        "#(nell'array 'genres' non ci sono tutti i generi ma solo alcuni di esempio)\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_genres(stringa):\n",
        "    genres = [\"acoustic\",\"afrobeat\",\"alt-rock\",\"alternative\",\"ambient\",\"anime\",\"black-metal\",\"blues\",\"bossanova\",\"brazil\",\"breakbeat\",\"british\",\"children\",\"chill\",\"classical\",\"club\",\"comedy\",\"country\",\"dance\",\"dancehall\",\"death-metal\",\"deep-house\",\"disco\",\"disney\",\"drum-and-bass\",\"dub\",\"dubstep\",\"edm\",\"electro\",\"electronic\",\"emo\",\"folk\",\"french\",\"funk\",\"garage\",\"german\",\"gospel\",\"goth\",\"groove\",\"grunge\",\"guitar\",\"happy\",\"hard-rock\",\"hardcore\",\"hardstyle\",\"heavy-metal\",\"hip-hop\",\"holidays\",\"house\",\"idm\",\"indian\",\"indie\",\"indie-pop\",\"industrial\",\"j-pop\",\"jazz\",\"k-pop\",\"kids\",\"latin\",\"latino\",\"metal\",\"metal-misc\",\"metalcore\",\"minimal-techno\",\"movies\",\"new-age\",\"opera\",\"party\",\"piano\",\"pop\",\"pop-film\",\"post-dubstep\",\"power-pop\",\"progressive-house\",\"psych-rock\",\"punk\",\"punk-rock\",\"r-n-b\",\"rainy-day\",\"reggae\",\"reggaeton\",\"road-trip\",\"rock\",\"rock-n-roll\",\"rockabilly\",\"romance\",\"sad\",\"salsa\",\"samba\",\"show-tunes\",\"singer-songwriter\",\"sleep\",\"songwriter\",\"soul\",\"soundtracks\",\"spanish\",\"study\",\"summer\",\"swedish\",\"synth-pop\",\"tango\",\"techno\",\"trance\",\"work-out\",\"world-music\"]\n",
        "    # Dividi la stringa in \"parole\" basate su spazi o altri simboli, usando regex per trovare tutte le parole\n",
        "    instruction, response = stringa.split('[/INST]')\n",
        "\n",
        "    parole = re.findall(r'\\b\\w+\\b', response)\n",
        "    parole_trovate = []\n",
        "\n",
        "    for parola in parole:\n",
        "\n",
        "        # Pulisce ogni parola dai simboli, mantenendo solo caratteri alfabetici\n",
        "        parola_pulita = re.sub(r'[^\\w]', '', parola)\n",
        "        # Controlla se una qualsiasi parola \"pulita\" è presente in genres\n",
        "        for genere in genres:\n",
        "            if re.search(r'\\b' + re.escape(parola_pulita) + r'\\b', genere, re.IGNORECASE):\n",
        "                # Aggiungi alla lista delle parole trovate se corrisponde e non è già presente\n",
        "                if genere not in parole_trovate:\n",
        "                    parole_trovate.append(genere)\n",
        "                break  # Interrompe il ciclo interno una volta trovata la corrispondenza\n",
        "        if len(parole_trovate) == 3:\n",
        "            break  # Interrompe il ciclo esterno una volta trovate 3 parole\n",
        "\n",
        "    return parole_trovate\n",
        "\n",
        "# print(parole_trovate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlLsHrgfsUer"
      },
      "source": [
        "## Flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAGaHVuPhw62"
      },
      "outputs": [],
      "source": [
        "# CODICE JAVASCRIPT PER FARE LA RICHIESTA AL MODELLO\n",
        "# SOSTITUISCI CON L'URL DELLA SESSIONE COLAB\n",
        "\"\"\"\n",
        "let data = {\n",
        "  text: \"songs with a lot of energy from 70s 80s\"\n",
        "};\n",
        "\n",
        "// Sostituisci 'URL_DEL_TUO_SERVER' con l'URL effettivo del server Flask\n",
        "fetch('IL-TUO-URL/uppercase', {\n",
        "  method: 'POST', // Metodo della richiesta\n",
        "  headers: {\n",
        "    'Content-Type': 'application/json', // Specifica che il corpo della richiesta è in formato JSON\n",
        "  },\n",
        "  body: JSON.stringify(data), // Trasforma l'oggetto `data` in una stringa JSON\n",
        "})\n",
        ".then(response => response.json()) // Converte la risposta in JSON\n",
        ".then(data => {\n",
        "  console.log('Success:', data); // Stampa i dati della risposta\n",
        "})\n",
        ".catch((error) => {\n",
        "  console.error('Error:', error); // Stampa l'errore se qualcosa va storto\n",
        "});\n",
        "\n",
        "let data = {\n",
        "    genres: [\"pop\", \"rock\", \"indie\"],\n",
        "    access_token: \"BQBpJxVg4Zwdj9e4hwCcybNQg3xxpkr4G8el9bGLZXrf_bVvn2Era8K4xQga8zfFZtL3m0qU5vAOA5OJTs2V-ms0IyvEWWlq1b3cCaLqnBbW5eb14Zg3_za08rUV5icbj9nHHGpSXdrdE44zUdheIT3DXwSpCvTk9Dn4IqmNu0A\"\n",
        "};\n",
        "\n",
        "// Sostituisci 'URL_DEL_TUO_SERVER' con l'URL effettivo del server Flask\n",
        "fetch('https://rgz5olderva-496ff2e9c6d22116-5000-colab.googleusercontent.com/createPlaylist', {\n",
        "  method: 'POST', // Metodo della richiesta\n",
        "  headers: {\n",
        "    'Content-Type': 'application/json', // Specifica che il corpo della richiesta è in formato JSON\n",
        "  },\n",
        "  body: JSON.stringify(data), // Trasforma l'oggetto `data` in una stringa JSON\n",
        "})\n",
        ".then(response => response.json()) // Converte la risposta in JSON\n",
        ".then(data => {\n",
        "  console.log('Success:', data); // Stampa i dati della risposta\n",
        "})\n",
        ".catch((error) => {\n",
        "  console.error('Error:', error); // Stampa l'errore se qualcosa va storto\n",
        "});\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dJFgvvCFJDl"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, send_from_directory, jsonify, request\n",
        "import os\n",
        "# from spotipy.oauth2 import SpotifyOAuth\n",
        "import random\n",
        "\n",
        "import requests\n",
        "from requests.auth import HTTPBasicAuth\n",
        "\n",
        "app = Flask(__name__, static_folder='/content/PlaylistCreator/frontend/build', static_url_path='')\n",
        "#app = Flask(__name__)\n",
        "# run_with_ngrok(app)\n",
        "\n",
        "# Spotify API credentials\n",
        "# SPOTIFY_CLIENT_ID = '08d52968d40a4cb999ddd47d784b5ac5'\n",
        "# SPOTIFY_CLIENT_SECRET = '12683b0d2847456b975fb25c57cd1604'\n",
        "# SPOTIFY_REDIRECT_URI = 'https://rgz5olderva-496ff2e9c6d22116-5000-colab.googleusercontent.com/'\n",
        "# SCOPE = 'user-top-read playlist-modify-public user-read-private'\n",
        "\n",
        "BASE_PROMPT = \"[INST] genres: [acoustic,afrobeat,alt-rock,alternative,ambient,anime,black-metal,blues,bossanova,brazil,breakbeat,british,children,chill,classical,club,comedy,country,dance,dancehall,death-metal,deep-house,disco,disney,drum-and-bass,dub,dubstep,edm,electro,electronic,emo,folk,french,funk,garage,german,gospel,goth,groove,grunge,guitar,happy,hard-rock,hardcore,hardstyle,heavy-metal,hip-hop,holidays,house,idm,indian,indie,indie-pop,industrial,j-pop,jazz,k-pop,kids,latin,latino,metal,metal-misc,metalcore,minimal-techno,movies,new-age,opera,party,piano,pop,pop-film,post-dubstep,power-pop,progressive-house,psych-rock,punk,punk-rock,r-n-b,rainy-day,reggae,reggaeton,road-trip,rock,rock-n-roll,rockabilly,romance,sad,salsa,samba,show-tunes,singer-songwriter,sleep,songwriter,soul,soundtracks,spanish,study,summer,swedish,synth-pop,tango,techno,trance,work-out,world-music] As an assistant, identify the three most suitable genres from the list above for the following description: '\"\n",
        "\n",
        "@app.route('/genres', methods=['POST'])\n",
        "def genres():\n",
        "    data = request.json  # Assume che i dati inviati siano in formato JSON\n",
        "    text = data.get('text', '')  # Ottiene la stringa dal campo 'text' del JSON ricevuto\n",
        "    if text:\n",
        "        model.eval()\n",
        "\n",
        "        prompt = BASE_PROMPT + text + \"' [/INST]\"\n",
        "        print(\"PLAYLIST DESCRIPTION: \" + text)\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=25)\n",
        "\n",
        "        parole_trovate = extract_genres(tokenizer.batch_decode(outputs)[0])\n",
        "\n",
        "        parole_trovate_str = ' '.join(parole_trovate)  # Converte la lista in una stringa\n",
        "        print(\"GENERI IDENTIFICATI DAL MODELLO: \", parole_trovate)\n",
        "        return jsonify({'text': parole_trovate_str})\n",
        "\n",
        "    else:\n",
        "        # Se non viene fornita alcuna stringa, invia un messaggio di errore\n",
        "        return jsonify({'error': 'No text provided'}), 400\n",
        "\n",
        "@app.route('/')\n",
        "def serve():\n",
        "    return send_from_directory(app.static_folder, 'index.html')\n",
        "\n",
        "@app.route('/<path:path>')\n",
        "def static_proxy(path):\n",
        "    file_name = path.split('/')[-1]\n",
        "    directory_name = os.path.join(app.static_folder, '/'.join(path.split('/')[:-1]))\n",
        "    return send_from_directory(directory_name, file_name)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(host='0.0.0.0', port=8084)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxoNFmB3aL-l"
      },
      "source": [
        "## Use model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVz9j2DKZVSZ"
      },
      "outputs": [],
      "source": [
        "# prompt = f\"\"\" [INST] genres: [acoustic,afrobeat,alt-rock,alternative,ambient,anime,black-metal,blues,bossanova,brazil,breakbeat,british,children,chill,classical,club,comedy,country,dance,dancehall,death-metal,deep-house,disco,disney,drum-and-bass,dub,dubstep,edm,electro,electronic,emo,folk,french,funk,garage,german,gospel,goth,groove,grunge,guitar,happy,hard-rock,hardcore,hardstyle,heavy-metal,hip-hop,holidays,house,idm,indian,indie,indie-pop,industrial,j-pop,jazz,k-pop,kids,latin,latino,metal,metal-misc,metalcore,minimal-techno,movies,new-age,opera,party,piano,pop,pop-film,post-dubstep,power-pop,progressive-house,psych-rock,punk,punk-rock,r-n-b,rainy-day,reggae,reggaeton,road-trip,rock,rock-n-roll,rockabilly,romance,sad,salsa,samba,show-tunes,singer-songwriter,sleep,songwriter,soul,soundtracks,spanish,study,summer,swedish,synth-pop,tango,techno,trance,work-out,world-music]\n",
        "# As an assistant, identify the three most suitable genres from the list above for the following description:\n",
        "# 'Nostalgic 80s hits that make you wish you were a teenager back then.' [/INST]\n",
        "# \"\"\"\n",
        "\n",
        "# model.eval()\n",
        "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=25)\n",
        "# print(tokenizer.batch_decode(outputs)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9JPodoWKslF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hAZtDcheYrn1",
        "uxoNFmB3aL-l"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}